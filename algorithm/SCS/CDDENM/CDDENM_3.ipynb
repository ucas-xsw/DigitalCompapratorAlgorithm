{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the objective function\n",
    "def objective(x):\n",
    "    return (x[0]**2 - 3*x[1] + 2)**2 + (x[0] - x[1] + 1)**2\n",
    "\n",
    "\n",
    "# Set up the optimization problem\n",
    "bounds = [(-10, 10)] * 10  # 10 variables, each between 0 and 10\n",
    "x0 = np.zeros(10)  # initial guess\n",
    "options = {'maxiter': 100}  # stop after 100 iterations\n",
    "callback = lambda xk: print(f\"Iteration {len(xk)}: {objective(xk)}\")\n",
    "# callback function that prints the current optimal value at each iteration\n",
    "\n",
    "# Define the hybrid optimization function\n",
    "def hybrid_optimization(x0):\n",
    "    allvecs = [x0]\n",
    "    for i in range(100):\n",
    "        de_step = differential_evolution_step(objective, allvecs[-1], bounds)\n",
    "        nm_step = nelder_mead_step(objective, de_step, options, callback)\n",
    "        allvecs.append(nm_step)\n",
    "    return allvecs\n",
    "\n",
    "# Define the differential evolution step\n",
    "def differential_evolution_step(objective, x, bounds, F=0.8, CR=0.7):\n",
    "    n = len(x)\n",
    "    candidate = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        idxs = list(range(n))\n",
    "        idxs.remove(i)\n",
    "        a, b, c = np.random.choice(idxs, size=3, replace=False)\n",
    "        candidate[i] = x[a] + F * (x[b] - x[c])\n",
    "        candidate[i] = np.clip(candidate[i], bounds[i][0], bounds[i][1])\n",
    "    if objective(candidate) < objective(x):\n",
    "        return candidate\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Define the Nelder-Mead step\n",
    "def nelder_mead_step(objective, x, options, callback):\n",
    "    result = {'x': x, 'fun': objective(x), 'nfev': 1}\n",
    "    allvecs = [result['x']]\n",
    "    for i in range(options['maxiter']):\n",
    "        simplex = np.array(allvecs[-1] + (np.identity(len(x)) * 0.05))\n",
    "        fval = [objective(x) for x in simplex]\n",
    "        idxs = np.argsort(fval)\n",
    "        simplex = simplex[idxs]\n",
    "        fval = np.array(fval)[idxs]\n",
    "        result['x'] = simplex[0]\n",
    "        result['fun'] = fval[0]\n",
    "        allvecs.append(result['x'])\n",
    "        callback(allvecs[-1])\n",
    "    return result['x']\n",
    "\n",
    "# Run the optimization\n",
    "allvecs = hybrid_optimization(x0)\n",
    "\n",
    "# Plot the curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(allvecs)), [objective(x) for x in allvecs])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Optimal Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the objective function\n",
    "def objective(x):\n",
    "    return (x[0]**2 - 3*x[1] + 2)**2 + (x[0] - x[1] + 1)**2\n",
    "\n",
    "\n",
    "# Set up the optimization problem\n",
    "bounds = [(-10, 10)] * 10  # 10 variables, each between 0 and 10\n",
    "x0 = np.zeros(10)  # initial guess\n",
    "options = {'maxiter': 100}  # stop after 100 iterations\n",
    "callback = lambda xk: print(f\"Iteration {len(xk)}: {objective(xk)}\")\n",
    "# callback function that prints the current optimal value at each iteration\n",
    "\n",
    "# Define the hybrid optimization function\n",
    "def hybrid_optimization(x0):\n",
    "    allvecs = [x0]\n",
    "    for i in range(100):\n",
    "        de_step = differential_evolution_step(objective, allvecs[-1], bounds)\n",
    "        nm_step = nelder_mead_step(objective, de_step, options, callback)\n",
    "        allvecs.append(nm_step)\n",
    "    return allvecs\n",
    "\n",
    "# Define the differential evolution step\n",
    "def differential_evolution_step(objective, x, bounds, F=0.8, CR=0.7):\n",
    "    n = len(x)\n",
    "    candidate = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        idxs = list(range(n))\n",
    "        idxs.remove(i)\n",
    "        a, b, c = np.random.choice(idxs, size=3, replace=False)\n",
    "        candidate[i] = x[a] + F * (x[b] - x[c])\n",
    "        candidate[i] = np.clip(candidate[i], bounds[i][0], bounds[i][1])\n",
    "    if objective(candidate) < objective(x):\n",
    "        return candidate\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Define the Nelder-Mead step\n",
    "def nelder_mead_step(objective, x, options, callback):\n",
    "    result = {'x': x, 'fun': objective(x), 'nfev': 1}\n",
    "    allvecs = [result['x']]\n",
    "    for i in range(options['maxiter']):\n",
    "        simplex = np.array(allvecs[-1] + (np.identity(len(x)) * 0.05))\n",
    "        fval = [objective(x) for x in simplex]\n",
    "        idxs = np.argsort(fval)\n",
    "        simplex = simplex[idxs]\n",
    "        fval = np.array(fval)[idxs]\n",
    "        result['x'] = simplex[0]\n",
    "        result['fun'] = fval[0]\n",
    "        allvecs.append(result['x'])\n",
    "        callback(allvecs[-1])\n",
    "    return result['x']\n",
    "\n",
    "# Run the optimization\n",
    "allvecs = hybrid_optimization(x0)\n",
    "\n",
    "# Plot the curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(allvecs)), [objective(x) for x in allvecs])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Optimal Value')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
